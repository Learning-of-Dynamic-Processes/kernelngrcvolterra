/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
/home/gballarin/hannah/Volterra/estimators/volt_funcs.py:17: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (Array(float64, 1, 'A', False, aligned=True), Array(float64, 1, 'A', False, aligned=True))
  Gram[i, j] = 1 + ld**2 * Gram0/(1-(tau**2)*(np.dot(training_input[i], training_input[j])))
Reached 100 hyperparameters
Best estimate so far: 1.014974750338312 with (0.1, 0.4, 0.0001, 100)
Reached 200 hyperparameters
Best estimate so far: 0.993009585127721 with (0.2, 0.4, 0.0001, 100)
Reached 300 hyperparameters
Best estimate so far: 0.9778236453135536 with (0.3, 0.2, 1e-05, 100)
Reached 400 hyperparameters
Best estimate so far: 0.9668374736829677 with (0.3, 0.3, 0.0001, 100)
Reached 500 hyperparameters
Best estimate so far: 0.9513339155417807 with (0.4, 0.4, 0.001, 100)
Reached 600 hyperparameters
Best estimate so far: 0.9291187077809019 with (0.5, 0.4, 0.001, 100)
Reached 700 hyperparameters
Best estimate so far: 0.9291187077809019 with (0.5, 0.4, 0.001, 100)
Reached 800 hyperparameters
Best estimate so far: 0.9195677792583373 with (0.6, 0.4, 0.001, 100)
Reached 900 hyperparameters
Best estimate so far: 0.9053143251549269 with (0.7, 0.6, 0.01, 100)
Reached 1000 hyperparameters
Best estimate so far: 0.9053143251549269 with (0.7, 0.6, 0.01, 100)
Reached 1100 hyperparameters
Best estimate so far: 0.8935886893588577 with (0.8, 0.6, 0.01, 100)
Reached 1200 hyperparameters
Best estimate so far: 0.8929939048050113 with (0.9, 0.6, 0.001, 100)
Best parameters found are (0.9, 0.6, 0.001, 100) with error 0.8929939048050113
Amount of time to run: 118.58017182350159
