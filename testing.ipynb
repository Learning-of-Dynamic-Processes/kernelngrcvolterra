{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShiftScale\n",
      "([array([[0, 1],\n",
      "       [2, 3]]), array([[1, 2],\n",
      "       [3, 4]])], 0, 1)\n",
      "([array([[ 8, 12],\n",
      "       [16, 20]]), array([[12, 16],\n",
      "       [20, 24]])], 2, 4)\n",
      "([array([[0, 4],\n",
      "       [2, 8]]), array([[ 1,  6],\n",
      "       [ 3, 10]])], [0, 1], [1, 2])\n",
      "([array([[0., 1.],\n",
      "       [2., 3.]]), array([[1., 2.],\n",
      "       [3., 4.]])], [0, -2], [1, 0.5])\n",
      "NormStd\n",
      "([array([[-1., -1.],\n",
      "       [ 1.,  1.]]), array([[0., 0.],\n",
      "       [2., 2.]])], array([-1., -2.]), array([1., 1.]))\n",
      "MinMax\n",
      "([array([[0., 0.],\n",
      "       [1., 1.]]), array([[0.5, 0.5],\n",
      "       [1.5, 1.5]])], array([-0., -1.]), array([0.5, 0.5]))\n",
      "([array([[0., 0.],\n",
      "       [2., 2.]]), array([[1., 1.],\n",
      "       [3., 3.]])], array([-0., -1.]), array([1., 1.]))\n",
      "ScaleL2\n",
      "([array([[0.        , 0.2773501 ],\n",
      "       [0.5547002 , 0.83205029]]), array([[0.2773501 , 0.5547002 ],\n",
      "       [0.83205029, 1.10940039]])], 0, 0.2773500981126146)\n",
      "[1. 2.] [1. 2.]\n",
      "[2. 3.] [2. 3.]\n",
      "1.0\n",
      "ScaleL2Shift\n",
      "([array([[-0.70710678, -0.70710678],\n",
      "       [ 0.70710678,  0.70710678]]), array([[0.        , 0.        ],\n",
      "       [1.41421356, 1.41421356]])], array([-1., -2.]), 0.7071067811865475)\n",
      "[0. 0.] [1. 2.]\n",
      "[0.70710678 0.70710678] [0.70710678 0.70710678]\n",
      "1.0\n",
      "([array([[0, 1],\n",
      "       [2, 3]]), array([[1, 2],\n",
      "       [3, 4]])], 0, 1)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from utils.normalisation import normalise_arrays\n",
    "\n",
    "# Generate a small dataset for checking normalisation by hand\n",
    "data_in = np.arange(0, 4, 1).reshape(-1, 2)\n",
    "data_out = np.arange(1, 5, 1).reshape(-1, 2)\n",
    "\n",
    "# ShiftScale function and normtype\n",
    "\n",
    "# Check default shift scale should throw out the same guy\n",
    "print(\"ShiftScale\")\n",
    "print(normalise_arrays([data_in, data_out], norm_type=\"ShiftScale\")) #( array([[0, 1], [2, 3]]), array([[1, 2], [3, 4]]) ), 0, 1)\n",
    "# Check shift scale for some standard example scalar example\n",
    "print(normalise_arrays([data_in, data_out], norm_type=\"ShiftScale\", shift=2, scale=4)) #( array([[0, 2], [4, 6]]), array([[2, 4], [6, 8]]) ), 2, 4)\n",
    "# Check shift scale for some example with array shifts and scales\n",
    "print(normalise_arrays([data_in, data_out], norm_type=\"ShiftScale\", shift=[0, 1], scale=[1, 2])) #( array([[0, 4], [2, 8]]), array([[1, 6], [3, 10]]) ), [0,1], [1,2]) \n",
    "# Check that unshift and unscaling gives the original datas\n",
    "print(normalise_arrays([ np.array([[0, 4], [2, 8]]), np.array([[1, 6], [3, 10]]) ], norm_type=\"ShiftScale\", shift=[0, -2], scale=[1, 1/2])) #( array([[0, 1], [2, 3]]), array([[1, 2], [3, 4]]) ), [0, -1], [1, 1/2])\n",
    "\n",
    "# NormStd\n",
    "print(\"NormStd\")\n",
    "print(normalise_arrays([data_in, data_out], norm_type=\"NormStd\")) # ([ [[1, -1], [1, 1]], [[0, 0], [2, 2]], [-1, -2], [1, 1])\n",
    "\n",
    "# MinMax \n",
    "print(\"MinMax\")\n",
    "# Check the default MinMax works\n",
    "print(normalise_arrays([data_in, data_out], norm_type=\"MinMax\")) # ([ [[0, 0], [1, 1]], [[1/2, 1/2], [3/2, 3/2] ], [0, -1], [1/2, 1/2])\n",
    "# Check that a custom MinMax works\n",
    "print(normalise_arrays([data_in, data_out], norm_type=\"MinMax\", minmax_range=(0, 2))) # ([ [[0, 0], [2, 2]], [[1, 1], [3, 3] ], [0, -1], [1, 1])\n",
    "\n",
    "# ScaleL2\n",
    "print(\"ScaleL2\")\n",
    "scalel2 = normalise_arrays([data_in, data_out], norm_type=\"ScaleL2\")\n",
    "print(scalel2) # ([ [[0, 1/sqrt(13)], [2/sqrt(13), 3/sqrt(13)]], [[1/sqrt(13), 2/sqrt(13)], [3/sqrt(13), 4/sqrt(13)] ], 0, 1/sqrt(13))\n",
    "# Check the mean is scaled but not the same\n",
    "print(np.sqrt(13)*np.mean(scalel2[0][0], axis=0), np.mean(data_in, axis=0))\n",
    "print(np.sqrt(13)*np.mean(scalel2[0][1], axis=0), np.mean(data_out, axis=0))\n",
    "# Check that the max norm of the first array is 1\n",
    "print(np.max([np.linalg.norm(z) for z in scalel2[0][0]]))\n",
    "\n",
    "# ScaleL2Shift\n",
    "print(\"ScaleL2Shift\")\n",
    "scalel2shift = normalise_arrays([data_in, data_out], norm_type=\"ScaleL2Shift\")\n",
    "print(scalel2shift) # ([ [[-1, -1], [1, 1]], [[-1/sqrt(2), -1/sqrt(2)], [1/sqrt(2), 1/sqrt(2)] ], [-1, -2], 1/sqrt(2))\n",
    "# Check the mean of the first array is now 0 and the mean of the second array is shifted in mean correctly\n",
    "print(np.mean(scalel2shift[0][0], axis=0), np.mean(data_in, axis=0))\n",
    "print(np.mean(scalel2shift[0][1], axis=0), scalel2shift[2]*(np.mean(data_out, axis=0) + scalel2shift[1]))\n",
    "# Check that the max norm of the first array is 1\n",
    "print(np.max([np.linalg.norm(z) for z in scalel2[0][0]]))\n",
    "\n",
    "# Check None really does nothing\n",
    "print(normalise_arrays([data_in, data_out], norm_type=None)) #( array([[0, 1], [2, 3]]), array([[1, 2], [3, 4]]) ), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n",
      "3.5\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.35\n",
      "0.35\n",
      "0.35\n",
      "0.35\n"
     ]
    }
   ],
   "source": [
    "# Check error functions\n",
    "\n",
    "from utils.errors import calculate_mse, calculate_nmse, calculate_wasserstein1err\n",
    "from utils.normalisation import normalise_arrays\n",
    "\n",
    "data_true = np.zeros((2, 2))\n",
    "data1 = np.arange(0, 4, 1).reshape(-1, 2)\n",
    "data2 = np.arange(1, 5, 1).reshape(-1, 2)\n",
    "\n",
    "# Check mse without shifting and scaling\n",
    "print(calculate_mse(data_true, data1))  # 3.5\n",
    "print(np.mean(np.mean(data1**2, axis=0)))\n",
    "\n",
    "# Check mse with shifting and scaling gives back the same as if the unshifted unscaled data was used\n",
    "data_normed, shift, scale = normalise_arrays([data1, data2], norm_type=\"ShiftScale\", shift=1, scale=2)\n",
    "print(calculate_mse(data_normed[0], data_normed[1], shift, scale))\n",
    "print(calculate_mse(data1, data2))\n",
    "\n",
    "# Check nmse \n",
    "print(calculate_nmse(data1, data_true)) # 1.0\n",
    "\n",
    "# Check nmse with shifting and scaling gives back the same as if the unshifted unscaled data was used\n",
    "data_normed, shift, scale = normalise_arrays([data1, data2], norm_type=\"ShiftScale\", shift=1, scale=2)\n",
    "print(calculate_nmse(data_normed[0], data_normed[1], shift, scale))\n",
    "print(calculate_nmse(data1, data2))\n",
    "\n",
    "# Check nmse with shifting and scaling gives back the same as if the unshifted unscaled data was used\n",
    "data_normed, shift, scale = normalise_arrays([data1, data2], norm_type=\"ShiftScale\", shift=1, scale=2)\n",
    "print(calculate_nmse(data_normed[0], data_normed[1], shift, scale))\n",
    "print(calculate_nmse(data1, data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([array([[0],\n",
      "       [1],\n",
      "       [2]]), array([[1],\n",
      "       [2],\n",
      "       [3]]), array([[3],\n",
      "       [4]]), array([[4],\n",
      "       [5]])], 0, 1)]\n",
      "[([array([[0],\n",
      "       [1]]), array([[1],\n",
      "       [2]]), array([[2],\n",
      "       [3]]), array([[3],\n",
      "       [4]])], 0, 1), ([array([[1],\n",
      "       [2]]), array([[2],\n",
      "       [3]]), array([[3],\n",
      "       [4]]), array([[4],\n",
      "       [5]])], 0, 1)]\n",
      "[array([[0.],\n",
      "       [1.]]), array([[2.],\n",
      "       [3.],\n",
      "       [4.]])]\n",
      "[array([[4],\n",
      "       [6]]), array([[ 8],\n",
      "       [10],\n",
      "       [12]])]\n",
      "[([array([[0. ],\n",
      "       [0.5],\n",
      "       [1. ]]), array([[0.5],\n",
      "       [1. ],\n",
      "       [1.5]]), array([[1.5],\n",
      "       [2. ]]), array([[2. ],\n",
      "       [2.5]])], array([-0.]), array([0.5]))]\n"
     ]
    }
   ],
   "source": [
    "# Check that the cv code splits data and normalises correctly\n",
    "\n",
    "import numpy as np\n",
    "from utils.crossvalidation import CrossValidate\n",
    "from utils.normalisation import normalise_arrays\n",
    "\n",
    "# Define a small dataset\n",
    "data_in = np.arange(0, 5, 1).reshape(-1, 1)\n",
    "data_out = np.arange(1, 6, 1).reshape(-1, 1)\n",
    "\n",
    "# Check the data splitting - with one train-validation set\n",
    "CV = CrossValidate(validation_parameters=[2, 2, 0], validation_type=\"rolling\", task=\"PathContinue\")\n",
    "print(CV.split_data_to_folds(data_in, data_out))\n",
    "\n",
    "# With multiple train-validation set\n",
    "CV = CrossValidate(validation_parameters=[2, 2, 1], validation_type=\"rolling\", task=\"PathContinue\")\n",
    "print(CV.split_data_to_folds(data_in, data_out))\n",
    "\n",
    "# Check with normalisation that its correct\n",
    "# Normalise arrays normally \n",
    "print(normalise_arrays([data_in[0:2], data_in[2:]], norm_type=\"MinMax\")[0])\n",
    "print(normalise_arrays([data_out[0:2], data_out[2:]], norm_type=\"ShiftScale\", shift=1, scale=2)[0])\n",
    "# Check that the splitting datafodls normalises it correctly\n",
    "CV = CrossValidate(validation_parameters=[2, 2, 0], validation_type=\"rolling\", task=\"PathContinue\",\n",
    "                   norm_type_in=\"MinMax\", norm_type_target=\"ShiftScale\", shift_target=1, scale_target=2)\n",
    "print(CV.split_data_to_folds(data_in, data_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.23588789]\n",
      " [1.23674888]\n",
      " [1.22177835]\n",
      " ...\n",
      " [1.05405358]\n",
      " [1.00188219]\n",
      " [0.95218652]]\n",
      "[[1.23588789]\n",
      " [1.23674888]\n",
      " [1.22177835]\n",
      " ...\n",
      " [1.05405358]\n",
      " [1.00188219]\n",
      " [0.95218652]]\n"
     ]
    }
   ],
   "source": [
    "# Sets the default math computation in numpy to not parallelise (might be MKL)\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'    \n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "from datagen.data_generate_dde import dde_rk45\n",
    "from systems.ddes import mackeyglass\n",
    "from utils.crossvalidation import CrossValidate\n",
    "from utils.normalisation import normalise_arrays\n",
    "from estimators.volt_funcs import Volterra\n",
    "from estimators.ngrc_funcs import NGRC\n",
    "\n",
    "from crossvalidation2 import CrossValidate as CrossValidate2\n",
    "# Create the MG dataset\n",
    "def init(t):\n",
    "    return 1.2\n",
    "\n",
    "mg_args = {'delay': 17, 'a': 0.2, 'b': 0.1, 'n': 10 }\n",
    "\n",
    "h = 0.02\n",
    "n_intervals = 200\n",
    "slicing = int(1 / h)\n",
    "\n",
    "data = dde_rk45(n_intervals, init, mackeyglass, h, mg_args)[1][::slicing]\n",
    "\n",
    "# Define the training and washout size\n",
    "ntrain = 3000\n",
    "washout = 2\n",
    "\n",
    "# Construct training input and teacher, testing input and teacher\n",
    "training_input_orig = data[0:ntrain-1] \n",
    "training_teacher_orig = data[1:ntrain]\n",
    "\n",
    "# Normalise training arrays if necessary\n",
    "normalisation_output = normalise_arrays([training_input_orig, training_teacher_orig], norm_type=None)\n",
    "training_input, training_teacher = normalisation_output[0]\n",
    "\n",
    "# Define the range of parameters for which you want to cross validate over\n",
    "ndelay_range = [2] \n",
    "deg_range = [2]\n",
    "reg_range = [0.001]\n",
    "param_ranges = [ndelay_range, deg_range, reg_range]\n",
    "\n",
    "# Define additional input parameters\n",
    "param_add = [washout, True]\n",
    "\n",
    "# Instantiate CV, split dataset, crossvalidate in parallel\n",
    "CV = CrossValidate(validation_parameters=[2000, 500, 100], validation_type=\"rolling\", manage_remainder=False, \n",
    "                    task=\"PathContinue\", norm_type_in=None, \n",
    "                    error_type=\"meansquare\", log_interval=100)\n",
    "cv_datasets = CV.split_data_to_folds(training_input, training_teacher)\n",
    "print(cv_datasets[-1][0][0])\n",
    "min_error, best_parameters = CV.crossvalidate(NGRC, cv_datasets, param_ranges, param_add, \n",
    "                                                num_processes=1, chunksize=1)    \n",
    "CV = CrossValidate2(validation_parameters=[2000, 500, 100], validation_type=\"rolling\", \n",
    "                    task=\"PathContinue\", norm_type=None, \n",
    "                    error_type=\"meansquare\", log_interval=100)\n",
    "cv_datasets2 = CV.split_data_to_folds(training_input, training_teacher)\n",
    "min_error2, best_parameters2 = CV.crossvalidate(NGRC, cv_datasets, param_ranges, param_add, \n",
    "                                                num_processes=1, chunksize=1) \n",
    "print(cv_datasets[-1][0][0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055381877141539596"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055357373291253745"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_error2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
