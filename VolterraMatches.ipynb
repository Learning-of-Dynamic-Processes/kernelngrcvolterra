{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff747d3-4340-4819-92bf-d1345ddcc039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Hannah/Documents/VSCode/Volterra\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'    \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import perf_funcs as perf\n",
    "import hickle as hkl\n",
    "from numba import njit\n",
    "from functools import partial\n",
    "import time\n",
    "import mat73\n",
    "from scipy.stats import loguniform, wasserstein_distance\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.preprocessing import KernelCenterer, StandardScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65df33-8d4f-4149-9454-8f8285452970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "#################### Scorers #########################\n",
    "######################################################\n",
    "\n",
    "def neg_calculate_nmse(y_true, y_pred):\n",
    "    # Calculate MSE\n",
    "    mse = np.mean((y_true - y_pred)**2, axis=0)\n",
    "    factor = np.mean((y_true)**2, axis=0)\n",
    "    neg_nmse = -np.mean(mse / factor)\n",
    "    return neg_nmse\n",
    "\n",
    "def mean_wasserstein_dist(y_true, y_pred):\n",
    "    was_dist=[]\n",
    "    ndim=np.shape(y_true)[1]\n",
    "    for i in range(ndim):\n",
    "        was_dist = np.append(was_dist, wasserstein_distance(y_true[:,i], y_pred[:,i]))\n",
    "    return np.mean(was_dist)\n",
    "\n",
    "def neg_calculate_mse(y_true, y_pred):\n",
    "    # Calculate MSE\n",
    "    neg_mse = -np.mean((y_true - y_pred)**2)\n",
    "    return neg_mse\n",
    "\n",
    "def set_scorer(scorer='None'):\n",
    "    if scorer=='neg_mse':\n",
    "        my_scorer = {'neg_mse': make_scorer(neg_calculate_mse, greater_is_better=True)}  \n",
    "        my_refit = 'neg_mse' \n",
    "        score_str = 'mean_test_neg_mse'\n",
    "    elif scorer=='neg_nmse':\n",
    "        my_scorer = {'neg_nmse': make_scorer(neg_calculate_nmse, greater_is_better=True)}  \n",
    "        my_refit = 'neg_nmse' \n",
    "        score_str = 'mean_test_neg_nmse'\n",
    "    elif scorer=='score':\n",
    "        my_scorer = None\n",
    "        my_refit = True\n",
    "        score_str = 'mean_test_score'\n",
    "    return my_scorer, my_refit, score_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b3084d-3021-46d5-8212-2cf05e33f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "\n",
    "################ Volterra Class ######################\n",
    "######################################################\n",
    "\n",
    "@njit\n",
    "def _volt_gram_fast_njit(X, Y, omega, tau):\n",
    "    nT_X, nT_Y = X.shape[0], Y.shape[0]\n",
    "    # Compute once only instead of in the loop\n",
    "    omega, tau = omega ** 2, tau ** 2\n",
    "    # Initialize the gram matrix with ones\n",
    "    Gram = np.ones((nT_X, nT_Y))\n",
    "    tau_XY = 1 - X @ Y.T * tau\n",
    "    \n",
    "    # Compute the first row and column of the Gram matrix\n",
    "    Gram[0, 0] += omega / (1 - omega) / tau_XY[0, 0]\n",
    "    for i in range(1, nT_X):\n",
    "        Gram[i, 0] += omega / (1 - omega) / tau_XY[i, 0]\n",
    "    for i in range(1, nT_Y):\n",
    "        Gram[0, i] += omega / (1 - omega) / tau_XY[0, i]\n",
    "\n",
    "    # Compute the rest of the Gram matrix\n",
    "    for i in range(1, nT_X):\n",
    "        tau_XY_i = tau_XY[i]\n",
    "        for j in range(1, nT_Y):\n",
    "            Gram[i, j] += omega * Gram[i-1, j-1] / tau_XY_i[j]\n",
    "    \n",
    "    return Gram\n",
    "\n",
    "def _volt_gram(X, Y, omega, tau):\n",
    "    nT_X = np.shape(X)[0]\n",
    "    nT_Y = np.shape(Y)[0]\n",
    "    Gram = np.zeros((nT_X, nT_Y))\n",
    "    Gram0 = 1/(1-omega**2)\n",
    "    for i in range(nT_X):\n",
    "        for j in range(nT_Y):\n",
    "            if i==0 or j==0:\n",
    "                Gram[i, j] = 1 + omega**2 * Gram0/(1-(tau**2)*(np.dot(X[i,:], Y[j,:])))\n",
    "            else:\n",
    "                Gram[i, j] = 1 + omega**2 * Gram[i-1,j-1]/(1-(tau**2)*(np.dot(X[i,:], Y[j,:])))\n",
    "    return Gram\n",
    "\n",
    "def Volterra_kernel_callable(X, Y, omega, tau, nwashout):\n",
    "    # print(tau)\n",
    "    # print(omega)\n",
    "    volt_K = _volt_gram_fast_njit(X, Y, omega, tau)\n",
    "    return volt_K\n",
    "\n",
    "class VolterraKernel(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, alpha=1, omega=0.1, tau=0.1, nwashout=0, ifscale_kernel=False, ifscale_y=False, ifcenter_kernel=False):\n",
    "        self.alpha = alpha\n",
    "        self.omega = omega\n",
    "        self.tau = tau\n",
    "        self.nwashout = nwashout\n",
    "        self.Volterra_kernel = partial(Volterra_kernel_callable, omega=self.omega, tau=self.tau, nwashout=self.nwashout)\n",
    "        self.regressor = KernelRidge(kernel=\"precomputed\", alpha=self.alpha)\n",
    "        self.ifscale_kernel = ifscale_kernel\n",
    "        self.ifscale_y = ifscale_y\n",
    "        self.ifcenter_kernel = ifcenter_kernel\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Transform to obtain Volterra kernel and fit kernel ridge regression\n",
    "        K_fit = self.Volterra_kernel(X, X)\n",
    "        K_fit = K_fit[self.nwashout:, self.nwashout:]\n",
    "        if self.ifcenter_kernel:\n",
    "            centerer = KernelCenterer()\n",
    "            K_fit = centerer.fit_transform(K_fit)\n",
    "            self.centerer = centerer\n",
    "            \n",
    "        self.X_fit_ = X.copy()\n",
    "        # Rescale kernel if needed\n",
    "        if self.ifscale_kernel:\n",
    "            self.scaler_K = StandardScaler().fit(K_fit)\n",
    "            K_fit = self.scaler_K.transform(K_fit)\n",
    "\n",
    "        if self.ifscale_y:\n",
    "            self.scaler_y = StandardScaler().fit(y)\n",
    "            y = self.scaler_y.transform(y)\n",
    "\n",
    "        self.K_fit_ = K_fit\n",
    "        #print(self.Volterra_kernel)\n",
    "        self.regressor.fit(self.K_fit_, y[self.nwashout:,:])\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Transform to obtain Volterra kernel and predict\n",
    "        K_test = self.Volterra_kernel(X, self.X_fit_) # Use X_fit, not K_fit\n",
    "        print(K_test)\n",
    "        K_test = K_test[:, self.nwashout:]\n",
    "        if self.ifcenter_kernel:\n",
    "            centerer = self.centerer\n",
    "            K_test = centerer.transform(K_test)\n",
    "            \n",
    "        if self.ifscale_kernel:\n",
    "            K_test = self.scaler_K.transform(K_test)\n",
    "\n",
    "        if self.ifscale_y:\n",
    "            return self.scaler_y.inverse_transform(self.regressor.predict(K_test))\n",
    "            \n",
    "        return self.regressor.predict(K_test)\n",
    "    \n",
    "    # Make alpha parameter 'cv-able'\n",
    "    def set_params(self, **params):\n",
    "        for k, v in params.items():\n",
    "            if k == \"nwashout\":\n",
    "                self.nwashout = v\n",
    "            if k == \"omega\":\n",
    "                self.omega = v\n",
    "            elif k == \"tau\":\n",
    "                self.tau = v\n",
    "            elif k == \"alpha\":\n",
    "                self.alpha=v\n",
    "                self.regressor.alpha = self.alpha    \n",
    "            else:\n",
    "                setattr(self.regressor, k, v)\n",
    "        if self.omega > np.sqrt(1 - (self.tau**2)):\n",
    "            print(self.tau)\n",
    "            print(self.omega)\n",
    "            self.omega = np.sqrt(1 - (self.tau**2))*0.99\n",
    "            print('became:')\n",
    "            print(self.omega)\n",
    "        self.Volterra_kernel = partial(Volterra_kernel_callable, \n",
    "                                       omega=self.omega, \n",
    "                                       tau=self.tau, \n",
    "                                       nwashout=self.nwashout)\n",
    "        self.regressor = KernelRidge(kernel=\"precomputed\", alpha = self.alpha)\n",
    "        #print(self.Volterra_kernel)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74468ce5-847b-43fa-b4d7-3730cb010623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "\n",
    "################ Load data ###########################\n",
    "######################################################\n",
    "\n",
    "matstruct_contents = mat73.loadmat(\"./datagen/BEKK_d15_data.mat\")\n",
    "returns = matstruct_contents['data_sim']\n",
    "epsilons = matstruct_contents['exact_epsilons']\n",
    "Ht_sim_vech = matstruct_contents['Ht_sim_vech']\n",
    "\n",
    "data_in = epsilons\n",
    "#data_out = returns\n",
    "data_out = Ht_sim_vech\n",
    "\n",
    "ndim = data_in.shape[1]\n",
    "nT = data_in.shape[0]\n",
    "ndim_output = data_out.shape[1]\n",
    "\n",
    "if nT>3760:\n",
    "    nT = 3760\n",
    "\n",
    "x = data_in[0:nT-1,:]\n",
    "#y = data_out[0:nT-1,:]**2*1000\n",
    "y = data_out[1:nT,0:ndim_output]*1000\n",
    "t_dispay = 300\n",
    "\n",
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, \n",
    "    test_size=0.2, \n",
    "    shuffle=False, \n",
    "    random_state=1)\n",
    "\n",
    "scaler_y = StandardScaler().fit(y_train)\n",
    "y_train_demeaned = scaler_y.transform(y_train)\n",
    "\n",
    "train_len = np.shape(x_train)[0]\n",
    "test_len = np.shape(x_test)[0]\n",
    "total_len = test_len + train_len\n",
    "\n",
    "M = np.max([np.linalg.norm(z) for z in x])\n",
    "x_train /= M\n",
    "x_test /= M\n",
    "\n",
    "set_my_scorer=\"score\"\n",
    "my_scorer, my_refit, score_str = set_scorer(set_my_scorer)\n",
    "     \n",
    "n_jobs = 100\n",
    "\n",
    "ifsave=True\n",
    "ifRandomSearch=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d231629-df3e-4c1d-b8e9-b773c840f20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0100958  1.01010335 1.01009017 ... 1.01010279 1.0100976  1.01009602]\n",
      " [1.01009682 1.01008837 1.01010687 ... 1.01010966 1.01009669 1.01009376]\n",
      " [1.01010407 1.0101074  1.0100908  ... 1.01009304 1.01010266 1.01010901]\n",
      " ...\n",
      " [1.01010248 1.01009254 1.01009852 ... 1.01010434 1.01010139 1.01010108]\n",
      " [1.01009558 1.01009567 1.01009431 ... 1.01009122 1.01010089 1.01008567]\n",
      " [1.0101043  1.01009161 1.01008828 ... 1.01007564 1.0100994  1.01010407]]\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "\n",
    "# Check that the Volterra kernel gives the same results on the testing set for some set of hyperparameters\n",
    "# With modified Gram matrix using my Gram matrix code\n",
    "test_volt_kernel1 = VolterraKernel()\n",
    "test_volt_kernel1.fit(x_train, y_train_demeaned)\n",
    "test_prediction1 = test_volt_kernel1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0fffeb-693a-46fe-b5ba-1e2d3484992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "\n",
    "# Check for my Volterra kernel prediction set\n",
    "from estimators.volt_funcs import Volterra\n",
    "test_volt_kernel2 = Volterra(ld_coef=0.1, tau_coef=0.1, reg=1, washout=0)   # Follow the same defaults\n",
    "test_volt_kernel2.Train(x_train, y_train_demeaned)\n",
    "test_prediction2 = test_volt_kernel2.Forecast(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac79a78-c843-47d6-993a-76167deeec6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[ 8.41487801e-05  1.51256099e-05  1.29824775e-04 ...  5.98599672e-05\n",
      "  -2.84523764e-04  4.22109810e-04]\n",
      " [-1.03571549e-03 -6.85935247e-04 -1.27130554e-03 ... -3.80784750e-04\n",
      "   7.86217559e-05  4.32546061e-04]\n",
      " [-6.48606055e-04 -9.05098567e-05  3.27837266e-04 ... -2.76237920e-04\n",
      "  -1.12151122e-04 -5.70746494e-04]\n",
      " ...\n",
      " [-7.09464937e-04 -2.34624089e-04 -5.60455458e-04 ... -3.65696696e-04\n",
      "  -2.24203087e-04 -3.48580229e-04]\n",
      " [-8.58795215e-04 -3.82239735e-04 -6.84032775e-04 ... -3.63015110e-04\n",
      "  -1.41424250e-05 -2.76493001e-04]\n",
      " [-1.73811644e-05 -6.53329903e-05  6.72694680e-04 ...  2.82001292e-04\n",
      "  -2.47711710e-04 -4.24892451e-04]]\n",
      "[[ 8.41483681e-05  1.51229414e-05  1.29824565e-04 ...  5.98593685e-05\n",
      "  -2.84525793e-04  4.22113682e-04]\n",
      " [-1.03571590e-03 -6.85937915e-04 -1.27130575e-03 ... -3.80785348e-04\n",
      "   7.86197274e-05  4.32549933e-04]\n",
      " [-6.48606467e-04 -9.05125252e-05  3.27837055e-04 ... -2.76238518e-04\n",
      "  -1.12153151e-04 -5.70742622e-04]\n",
      " ...\n",
      " [-7.09465349e-04 -2.34626758e-04 -5.60455669e-04 ... -3.65697294e-04\n",
      "  -2.24205115e-04 -3.48576357e-04]\n",
      " [-8.58795627e-04 -3.82242403e-04 -6.84032985e-04 ... -3.63015708e-04\n",
      "  -1.41444534e-05 -2.76489129e-04]\n",
      " [-1.73815760e-05 -6.53356587e-05  6.72694470e-04 ...  2.82000694e-04\n",
      "  -2.47713738e-04 -4.24888579e-04]]\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "\n",
    "print(np.allclose(test_prediction1, test_prediction2))\n",
    "print(test_prediction1)\n",
    "print(test_prediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f3fab-6230-4ee7-a173-defd6ca60376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.01012459 1.01010067 1.0101005  ... 1.01010834 1.01010919 1.01010682]\n",
      " [1.01010067 1.01012761 1.01010281 ... 1.01010963 1.01010706 1.01009843]\n",
      " [1.0101005  1.01010281 1.01015234 ... 1.01009692 1.01010714 1.01009533]\n",
      " ...\n",
      " [1.01010834 1.01010963 1.01009692 ... 1.01015015 1.01011308 1.01009448]\n",
      " [1.01010919 1.01010706 1.01010714 ... 1.01011308 1.01013447 1.01009661]\n",
      " [1.01010682 1.01009843 1.01009533 ... 1.01009448 1.01009661 1.01013031]]\n",
      "[[1.01012459 1.01010067 1.0101005  ... 1.01010834 1.01010919 1.01010682]\n",
      " [1.01010067 1.01012761 1.01010281 ... 1.01010963 1.01010706 1.01009843]\n",
      " [1.0101005  1.01010281 1.01015234 ... 1.01009692 1.01010714 1.01009533]\n",
      " ...\n",
      " [1.01010834 1.01010963 1.01009692 ... 1.01015015 1.01011308 1.01009448]\n",
      " [1.01010919 1.01010706 1.01010714 ... 1.01011308 1.01013447 1.01009661]\n",
      " [1.01010682 1.01009843 1.01009533 ... 1.01009448 1.01009661 1.01013031]]\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "\n",
    "# Check to make sure that the Gram matrix is the same\n",
    "\n",
    "print(test_volt_kernel1.K_fit_)\n",
    "print(test_volt_kernel2.Gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa30ed0-b50f-432e-a51b-3ecd51933aac",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VolterraKernel' object has no attribute 'K_fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m/Users/Hannah/Documents/VSCode/Volterra/bekk_LG.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %% \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Check to make sure that the Gram matrix is the same\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mallclose(test_volt_kernel1\u001b[39m.\u001b[39;49mK_fit, test_volt_kernel2\u001b[39m.\u001b[39mGram))\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(test_volt_kernel1\u001b[39m.\u001b[39mK_fit_)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(test_volt_kernel2\u001b[39m.\u001b[39mGram)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VolterraKernel' object has no attribute 'K_fit'"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "\n",
    "# Check to make sure that the Gram matrix is the same\n",
    "print(np.allclose(test_volt_kernel1.K_fit, test_volt_kernel2.Gram))\n",
    "print(test_volt_kernel1.K_fit_)\n",
    "print(test_volt_kernel2.Gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e2cb81-6bc5-4dd8-a51f-58506f0db381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[1.01012459 1.01010067 1.0101005  ... 1.01010834 1.01010919 1.01010682]\n",
      " [1.01010067 1.01012761 1.01010281 ... 1.01010963 1.01010706 1.01009843]\n",
      " [1.0101005  1.01010281 1.01015234 ... 1.01009692 1.01010714 1.01009533]\n",
      " ...\n",
      " [1.01010834 1.01010963 1.01009692 ... 1.01015015 1.01011308 1.01009448]\n",
      " [1.01010919 1.01010706 1.01010714 ... 1.01011308 1.01013447 1.01009661]\n",
      " [1.01010682 1.01009843 1.01009533 ... 1.01009448 1.01009661 1.01013031]]\n",
      "[[1.01012459 1.01010067 1.0101005  ... 1.01010834 1.01010919 1.01010682]\n",
      " [1.01010067 1.01012761 1.01010281 ... 1.01010963 1.01010706 1.01009843]\n",
      " [1.0101005  1.01010281 1.01015234 ... 1.01009692 1.01010714 1.01009533]\n",
      " ...\n",
      " [1.01010834 1.01010963 1.01009692 ... 1.01015015 1.01011308 1.01009448]\n",
      " [1.01010919 1.01010706 1.01010714 ... 1.01011308 1.01013447 1.01009661]\n",
      " [1.01010682 1.01009843 1.01009533 ... 1.01009448 1.01009661 1.01013031]]\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "\n",
    "# Check to make sure that the Gram matrix is the same\n",
    "print(np.allclose(test_volt_kernel1.K_fit_, test_volt_kernel2.Gram))\n",
    "print(test_volt_kernel1.K_fit_)\n",
    "print(test_volt_kernel2.Gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1ba1d-f9de-4709-86a3-a7c10025a112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048006750833792196"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% \n",
    "\n",
    "# Check that the error functions all run correctly \n",
    "\n",
    "from utils.errors import calculate_mse, calculate_nmse, calculate_wasserstein1err\n",
    "\n",
    "neg_calculate_mse(y_test, test_prediction1)\n",
    "calculate_mse(y_test, test_prediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda5583-8c91-4dbb-9d45-26d606b63f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.048006750668746746\n",
      "0.048006750833792196\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "\n",
    "# Check that the error functions all run correctly \n",
    "\n",
    "from utils.errors import calculate_mse, calculate_nmse, calculate_wasserstein1err\n",
    "\n",
    "print(neg_calculate_mse(y_test, test_prediction1))\n",
    "print(calculate_mse(y_test, test_prediction2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f02a9-cd97-47ad-ba41-ce4cf149a8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.048006750668746746\n",
      "0.048006750833792196\n",
      "-1.0000104793684867\n",
      "1.0000104906208724\n",
      "0.15109413314255987\n",
      "18.13129606083808\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "\n",
    "# Check that the error functions all run correctly \n",
    "\n",
    "from utils.errors import calculate_mse, calculate_nmse, calculate_wasserstein1err\n",
    "\n",
    "print(neg_calculate_mse(y_test, test_prediction1))\n",
    "print(calculate_mse(y_test, test_prediction2))\n",
    "\n",
    "print(neg_calculate_nmse(y_test, test_prediction1))\n",
    "print(calculate_nmse(y_test, test_prediction2))\n",
    "\n",
    "print(mean_wasserstein_dist(y_test, test_prediction1))\n",
    "print(calculate_wasserstein1err(y_test, test_prediction2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58962a7-2d0d-4ff2-8494-a6ebfe73e797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.048006750668746746\n",
      "0.048006750833792196\n",
      "-1.0000104793684867\n",
      "1.0000104906208724\n",
      "0.15109413314255987\n",
      "0.1510941338403173\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "\n",
    "# Check that the error functions all run correctly \n",
    "\n",
    "from utils.errors import calculate_mse, calculate_nmse, calculate_wasserstein1err\n",
    "\n",
    "print(neg_calculate_mse(y_test, test_prediction1))\n",
    "print(calculate_mse(y_test, test_prediction2))\n",
    "\n",
    "print(neg_calculate_nmse(y_test, test_prediction1))\n",
    "print(calculate_nmse(y_test, test_prediction2))\n",
    "\n",
    "print(mean_wasserstein_dist(y_test, test_prediction1))\n",
    "print(calculate_wasserstein1err(y_test, test_prediction2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
